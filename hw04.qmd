---
title: "hw04"
author: "Shashwat Singh"
format: html
editor: visual
description: "Regression in R"
---

## **Install Required Packages**

```{r}
# Required packages
if (!require(pacman))
  install.packages("pacman")

pacman::p_load(tidymodels,
               tidyverse,
               ranger,
               randomForest,
               glmnet,
               gridExtra)

# Global ggplot theme
theme_set(theme_bw() + theme(legend.position = "top"))
```

Regression is a modeling technique for predicting quantitative-valued target attributes. The goals for this tutorial are as follows: 1. To provide examples of using different regression methods from the tidymodels package.

2. To demonstrate the problem of model overfitting due to correlated attributes in the data.

3. To illustrate how regularization can be used to avoid model overfitting.

## **Synthetic Data Generation**

To illustrate how linear regression works, we first generate a random 1-dimensional vector of predictor variables, x, from a uniform distribution. The response variable y has a linear relationship with x according to the following equation: y = -3x + 1 + epsilon, where epsilon corresponds to random noise sampled from a Gaussian distribution with mean 0 and standard deviation of 1.

```{r}
# Parameters
seed <- 1            # seed for random number generation 
numInstances <- 200  # number of data instances

# Set seed
set.seed(seed)

# Generate data
X <- matrix(runif(numInstances), ncol=1)
y_true <- -3*X + 1 
y <- y_true + matrix(rnorm(numInstances), ncol=1)

# Plot
ggplot() +
  geom_point(aes(x=X, y=y), color="black") +
  geom_line(aes(x=X, y=y_true), color="blue", linewidth=1) +
  ggtitle('True function: y = -3X + 1') +
  xlab('X') +
  ylab('y')
```

## **Multiple Linear Regression** 

We will use Python's scikit-learn package to fit a multiple linear regression (MLR) model.

Given a training set X,y MLR is designed to learn f(X,w)=X^T^w +w~0~ by minimizing the following loss function given a training set

L(y,f(X,w)) = (i=1 to n)âˆ‘ \|\|y~i-~ X~i~w-w~0~\|\|

where w (slope) and w0 (intercept) are the regression coefficients.

Given the input dataset, the following steps are performed:

1\. Split the input data into their respective training and test sets.

2\. Fit multiple linear regression to the training data.

3\. Apply the model to the test data.

4\. Evaluate the performance of the model.

5\. Postprocessing: Visualizing the fitted model.
